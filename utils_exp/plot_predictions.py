"""
Plotting utilities for time series predictions.

This module provides functions to visualize predictions generated by the
_save_predictions method in MLExperimentFacade, allowing analysis of model
performance across different time series (item_ids).
"""

import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import numpy as np
from pathlib import Path
from typing import Optional
import logging

logger = logging.getLogger(__name__)


def plot_predictions_by_item(
    predictions_df: pd.DataFrame,
    output_dir: Optional[Path] = None,
    figsize: tuple = (16, 8),
    dpi: int = 100,
) -> None:
    """
    Plot predictions as proper time series for each unique combination.
    
    Creates one plot per unique combination of (model_name, experiment_name, 
    item_id, context_length, prediction_length), showing continuous time series
    with actual values and predicted values as separate lines.
    
    Parameters
    ----------
    predictions_df
        DataFrame from _save_predictions with columns:
        - item_id: Identifier for the time series
        - forecast_start: Start date of forecast
        - horizon_step: Step in the prediction horizon (1-indexed)
        - actual_value: Ground truth value
        - predicted_mean: Model's point prediction
        - model_name, experiment_name, context_length, prediction_length: Metadata
    output_dir
        Directory to save plots. If None, plots are displayed interactively.
    figsize
        Figure size as (width, height) in inches.
    dpi
        Resolution of saved figures.
    """
    
    # Group by all unique series identifiers
    group_cols = ["model_name", "experiment_name", "item_id", "context_length", "prediction_length"]
    grouped = predictions_df.groupby(group_cols)
    
    total_series = len(grouped)
    logger.info(f"Plotting {total_series} unique time series combinations")
    
    for idx, (group_keys, group_data) in enumerate(grouped, 1):
        model_name, experiment_name, item_id, context_length, prediction_length = group_keys
        logger.info(f"Processing series {idx}/{total_series}: {item_id} - {model_name}")
        
        # Sort by window_index and horizon_step to ensure temporal order
        group_data = group_data.sort_values(["window_index", "horizon_step"])
        
        # Create continuous time series by concatenating all windows
        # Each window represents a different forecast, so we plot them sequentially
        
        # Convert forecast_start to datetime if it's a string
        group_data["forecast_start_dt"] = pd.to_datetime(group_data["forecast_start"])
        
        # Calculate absolute timestamp for each prediction
        # Assuming horizon_step is 1-indexed and represents steps forward
        group_data["timestamp"] = group_data.apply(
            lambda row: row["forecast_start_dt"] + pd.Timedelta(days=row["horizon_step"] - 1),
            axis=1
        )
        
        # Sort by timestamp for proper time series visualization
        group_data = group_data.sort_values("timestamp")
        
        # Create figure
        fig, ax = plt.subplots(figsize=figsize, dpi=dpi)
        
        # Plot actual values
        ax.plot(
            group_data["timestamp"],
            group_data["actual_value"],
            "-",
            label="Actual values",
            color="#2E86AB",  # Blue
            linewidth=2,
            marker="o",
            markersize=4,
            markevery=max(1, len(group_data) // 50),  # Show markers but not too many
            zorder=3,
        )
        
        # Plot predicted values
        ax.plot(
            group_data["timestamp"],
            group_data["predicted_mean"],
            "-",
            label="Predicted values",
            color="#A23B72",  # Magenta/Purple
            linewidth=2,
            marker="s",
            markersize=4,
            markevery=max(1, len(group_data) // 50),
            alpha=0.85,
            zorder=2,
        )
        
        # Formatting
        ax.set_xlabel("Time", fontsize=12, fontweight="bold")
        ax.set_ylabel("Value", fontsize=12, fontweight="bold")
        ax.set_title(
            f"Time Series: {item_id}\n"
            f"Model: {model_name} | Experiment: {experiment_name}\n"
            f"Context Length: {context_length} | Prediction Length: {prediction_length}",
            fontsize=13,
            fontweight="bold",
        )
        ax.grid(True, alpha=0.3, linestyle="--", linewidth=0.8)
        ax.legend(loc="best", fontsize=11, framealpha=0.9)
        
        # Format x-axis dates
        ax.xaxis.set_major_formatter(mdates.DateFormatter("%Y-%m-%d"))
        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha="right")
        
        plt.tight_layout()
        
        # Save or show
        if output_dir:
            output_dir = Path(output_dir)
            output_dir.mkdir(parents=True, exist_ok=True)
            
            # Create sanitized filename with all identifiers
            safe_name = f"{model_name}_{experiment_name}_{item_id}_ctx{context_length}_pred{prediction_length}"
            safe_name = safe_name.replace("/", "_").replace("\\", "_").replace(" ", "_")
            filename = output_dir / f"{safe_name}.png"
            
            fig.savefig(filename, dpi=dpi, bbox_inches="tight")
            logger.info(f"Saved plot to {filename}")
        else:
            plt.show()
        
        plt.close(fig)


def plot_aggregated_comparison(
    predictions_df: pd.DataFrame,
    output_path: Optional[Path] = None,
    figsize: tuple = (14, 8),
    dpi: int = 100,
) -> None:
    """
    Create an aggregated comparison plot across all items.
    
    Shows aggregated metrics (mean, std) for actual vs predicted across
    all time series and all windows.
    
    Parameters
    ----------
    predictions_df
        DataFrame from _save_predictions.
    output_path
        Path to save the plot. If None, displays interactively.
    figsize
        Figure size as (width, height) in inches.
    dpi
        Resolution of saved figures.
    """
    
    # Aggregate by horizon_step across all items and windows
    aggregated = predictions_df.groupby("horizon_step").agg({
        "actual_value": ["mean", "std"],
        "predicted_mean": ["mean", "std"],
    }).reset_index()
    
    # Flatten column names
    aggregated.columns = [
        "_".join(col).strip("_") if col[1] else col[0]
        for col in aggregated.columns.values
    ]
    
    fig, ax = plt.subplots(figsize=figsize, dpi=dpi)
    
    horizon_steps = aggregated["horizon_step"].values
    actual_mean = aggregated["actual_value_mean"].values
    actual_std = aggregated["actual_value_std"].values
    predicted_mean = aggregated["predicted_mean_mean"].values
    predicted_std = aggregated["predicted_mean_std"].values
    
    # Plot means with error bands (±1 std)
    ax.errorbar(
        horizon_steps,
        actual_mean,
        yerr=actual_std,
        fmt="o-",
        label="Actual (mean ± std)",
        color="black",
        linewidth=2,
        markersize=6,
        capsize=5,
        zorder=3,
    )
    
    ax.errorbar(
        horizon_steps,
        predicted_mean,
        yerr=predicted_std,
        fmt="s--",
        label="Predicted (mean ± std)",
        color="blue",
        linewidth=2,
        markersize=6,
        capsize=5,
        alpha=0.7,
        zorder=2,
    )
    
    # Formatting
    ax.set_xlabel("Horizon Step", fontsize=12, fontweight="bold")
    ax.set_ylabel("Aggregated Value", fontsize=12, fontweight="bold")
    ax.set_title(
        f"Aggregated Comparison: Actual vs Predicted\n"
        f"Across All Time Series",
        fontsize=13,
        fontweight="bold",
    )
    ax.grid(True, alpha=0.3, linestyle="--")
    ax.legend(loc="best", fontsize=11)
    
    plt.tight_layout()
    
    if output_path:
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        fig.savefig(output_path, dpi=dpi, bbox_inches="tight")
        logger.info(f"Saved aggregated plot to {output_path}")
    else:
        plt.show()
    
    plt.close(fig)


def load_and_plot(
    predictions_path: Path,
    output_dir: Optional[Path] = None,
    show_aggregated: bool = False,
) -> None:
    """
    Load predictions from parquet file and generate all plots.
    
    Convenience function to load predictions and generate time series plots
    for each unique combination of (model, experiment, item, context, prediction length).
    
    Parameters
    ----------
    predictions_path
        Path to predictions.parquet file.
    output_dir
        Directory to save plots. If None, displays interactively.
    show_aggregated
        If True, also generate aggregated comparison plot.
    """
    
    logger.info(f"Loading predictions from {predictions_path}")
    predictions_df = pd.read_parquet(predictions_path)
    
    logger.info(f"Loaded {len(predictions_df)} prediction records")
    logger.info(f"Unique items: {predictions_df['item_id'].nunique()}")
    logger.info(f"Unique models: {predictions_df['model_name'].nunique()}")
    logger.info(f"Unique experiments: {predictions_df['experiment_name'].nunique()}")
    logger.info(f"Unique windows: {predictions_df['window_index'].nunique()}")
    
    # Create individual time series plots
    if output_dir:
        individual_dir = Path(output_dir) / "timeseries_plots"
    else:
        individual_dir = None
    
    plot_predictions_by_item(
        predictions_df,
        output_dir=individual_dir,
    )
    
    # Create aggregated plot
    if show_aggregated:
        if output_dir:
            agg_path = Path(output_dir) / "aggregated_comparison.png"
        else:
            agg_path = None
        
        plot_aggregated_comparison(predictions_df, output_path=agg_path)


if __name__ == "__main__":
    # Example usage
    import sys
    
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )
    
    if len(sys.argv) < 2:
        print("Usage: python plot_predictions.py <predictions_parquet_path> [output_dir] [--aggregated]")
        print("\nExample:")
        print("  python plot_predictions.py ./artifacts/predictions/predictions.parquet ./artifacts")
        print("  python plot_predictions.py ./artifacts/predictions/predictions.parquet ./artifacts --aggregated")
        sys.exit(1)
    
    predictions_path = Path(sys.argv[1])
    output_dir = Path(sys.argv[2]) if len(sys.argv) > 2 else None
    show_aggregated = "--aggregated" in sys.argv
    
    load_and_plot(predictions_path, output_dir=output_dir, show_aggregated=show_aggregated)
